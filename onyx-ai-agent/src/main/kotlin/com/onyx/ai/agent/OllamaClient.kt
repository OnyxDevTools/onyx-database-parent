package com.onyx.ai.agent

import com.onyx.ai.agent.model.TaskResponse
import io.ktor.client.*
import io.ktor.client.engine.cio.*
import io.ktor.client.plugins.contentnegotiation.*
import io.ktor.client.request.*
import io.ktor.client.statement.*
import io.ktor.http.*
import io.ktor.serialization.kotlinx.json.*
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.withContext
import kotlinx.serialization.json.*

class OllamaClient(
    /** Model name ‚Äì change as you wish (e.g. "codellama:13b", "gpt-oss:20b", "gpt-4o") */
    internal val model: String = "gpt-oss:20b",

    /** Base URL of the *actual* Ollama server (or an OpenAI‚Äëcompatible proxy). */
    internal val baseUrl: String = "https://ollama.com",   // <-- most likely change needed

    /** Secret bearer token ‚Äì required by Ollama as of v0.1.27 and by every proxy that expects a key */
    private val apiKey: String
) {

    /* -------------------------------------------------------------
       Ktor HTTP client ‚Äì JSON aware, coroutine friendly
       ------------------------------------------------------------- */
    internal val http = HttpClient(CIO) {
        install(ContentNegotiation) {
            json(Json { ignoreUnknownKeys = true })
        }
    }

    /** -------------------------------------------------------------
    1Ô∏è‚É£  System prompt that *forces* JSON‚Äëonly output.
    ------------------------------------------------------------- */
    private val systemPrompt = """
        You are a JSON‚Äëonly assistant that helps with coding tasks.
        
        CRITICAL INSTRUCTIONS:
        - You MUST respond with ONLY a JSON object, nothing else
        - Do NOT use tool_calls, function calls, or any external tools
        - Do NOT wrap JSON in markdown code blocks or fences
        - Do NOT add explanatory text before or after the JSON
        - Do NOT use repo_browser, apply_patch, or any other tools
        
        Your response must be a valid JSON object matching this exact schema:
        {
          "tasks": [
            {
              "action": "create_file|edit_file|delete_file|run_command",
              "path": "<file-path-when-needed>",
              "content": "<file-content-when-needed>",
              "instruction": "<command-when-needed>"
            }
          ]
        }
        
        Available actions:
        - "create_file": Create a new file (requires path and content)
        - "edit_file": Modify existing file (requires path and content) 
        - "delete_file": Remove a file (requires path)
        - "run_command": Execute shell command (requires instruction)
        
        Example valid response:
        {"tasks":[{"action":"create_file","path":"src/Example.kt","content":"fun main() { println(\"Hello\") }"}]}
    """.trimIndent()

    /** -------------------------------------------------------------
    The JSON‚Äëschema we send to Ollama (only used when talking to a *real* Ollama server).
    ------------------------------------------------------------- */
    private val taskSchema = JsonObject(
        mapOf(
            "type" to JsonPrimitive("object"),
            "properties" to JsonObject(
                mapOf(
                    "tasks" to JsonObject(
                        mapOf(
                            "type" to JsonPrimitive("array"),
                            "items" to JsonObject(
                                mapOf(
                                    "type" to JsonPrimitive("object"),
                                    "properties" to JsonObject(
                                        mapOf(
                                            "action" to JsonObject(
                                                mapOf(
                                                    "type" to JsonPrimitive("string"),
                                                    "enum" to JsonArray(
                                                        listOf(
                                                            JsonPrimitive("create_file"),
                                                            JsonPrimitive("edit_file"),
                                                            JsonPrimitive("delete_file"),
                                                            JsonPrimitive("run_command")
                                                        )
                                                    )
                                                )
                                            ),
                                            "path" to JsonObject(mapOf("type" to JsonPrimitive("string"))),
                                            "content" to JsonObject(mapOf("type" to JsonPrimitive("string"))),
                                            "instruction" to JsonObject(mapOf("type" to JsonPrimitive("string")))
                                        )
                                    ),
                                    "required" to JsonArray(listOf(JsonPrimitive("action")))
                                )
                            )
                        )
                    )
                )
            ),
            "required" to JsonArray(listOf(JsonPrimitive("tasks")))
        )
    )

    /** -------------------------------------------------------------
    Helper ‚Äì adds   Authorization: Bearer <apiKey>
    ------------------------------------------------------------- */
    private fun HttpRequestBuilder.bearerHeader() {
        header(HttpHeaders.Authorization, "Bearer $apiKey")
    }

    /** -------------------------------------------------------------
    2Ô∏è‚É£  Ask the model for a **structured list of tasks**.
    ------------------------------------------------------------- */
    suspend fun askForTasks(userPrompt: String): TaskResponse = withContext(Dispatchers.IO) {
        askForTasksInternal(userPrompt)
    }
    
    /** Overloaded version that accepts chat history */
    suspend fun askForTasks(messages: List<ChatHistory.Msg>): TaskResponse = withContext(Dispatchers.IO) {
        val lastUserMessage = messages.lastOrNull { it.role == "user" }?.content 
            ?: "Continue with the previous task"
        askForTasksInternal(lastUserMessage, messages)
    }
    
    private suspend fun askForTasksInternal(userPrompt: String, previousMessages: List<ChatHistory.Msg>? = null): TaskResponse {
        /* --------- Build the request body ----------------------- */
        val body = buildJsonObject {
            put("model", model)

            // ---- messages ----------------------------------------------------
            put("messages", buildJsonArray {
                // system message ‚Äì bans tool calls & forces JSON
                add(buildJsonObject {
                    put("role", "system")
                    put("content", systemPrompt)
                })
                
                // Add previous messages if provided
                previousMessages?.forEach { msg ->
                    if (msg.role != "system") { // Don't duplicate system messages
                        add(buildJsonObject {
                            put("role", msg.role)
                            put("content", msg.content)
                        })
                    }
                }
                
                // actual user request
                add(buildJsonObject {
                    put("role", "user")
                    put("content", userPrompt)
                })
            })

            put("stream", false)

            // -----------------------------------------------------------------
            // ---- Two possible flavours ‚Äì pick the one that matches your backend
            // -----------------------------------------------------------------
            if (baseUrl.contains("ollama", ignoreCase = true)) {
                // Pure Ollama server ‚Äì it understands the `format` key
                put("format", taskSchema)
            } else {
                // OpenAI‚Äëcompatible proxy ‚Äì use `options.response_format`
                put("options", buildJsonObject {
                    put("response_format", "json_object")
                    // Disable tools (OpenAI 1.0+)
                    put("tool_choice", "none")
                })
            }
        }

        /* --------- Send the HTTP request ------------------------ */
        val raw = http.post("$baseUrl/api/chat") {
            contentType(ContentType.Application.Json)
            bearerHeader()
            setBody(body)
        }.bodyAsText()

        // -----------------------------------------------------------------
        // 3Ô∏è‚É£ Show the raw payload ‚Äì helps you debug the next time
        // -----------------------------------------------------------------
        println("üü¢ Raw HTTP response:\n$raw")

        // -----------------------------------------------------------------
        // 4Ô∏è‚É£ Extract the assistant's `content` field (the model's reply)
        // -----------------------------------------------------------------
        val outer = Json.parseToJsonElement(raw).jsonObject
        val messageObj = outer["message"]?.jsonObject
            ?: error("Response does not contain a `message` object")

        // Some proxies put the answer into `content`, others into `tool_calls`,
        // `thinking` etc. We first try `content`.
        val rawContent = messageObj["content"]?.jsonPrimitive?.contentOrNull
            ?: messageObj["thinking"]?.jsonPrimitive?.contentOrNull
            ?: ""

        // -----------------------------------------------------------------
        // 5Ô∏è‚É£ Guard‚Äërail: pull out the first JSON object that appears
        // -----------------------------------------------------------------
        val jsonOnly = extractJsonObject(rawContent)

        // -----------------------------------------------------------------
        // 6Ô∏è‚É£ Deserialize to our DTO
        // -----------------------------------------------------------------
        return Json.decodeFromString<TaskResponse>(jsonOnly)
    }

    /** -------------------------------------------------------------
    3Ô∏è‚É£  Plain‚Äëtext chat ‚Äì used for summarising, follow‚Äëup questions, etc.
    ------------------------------------------------------------- */
    suspend fun chatPlain(messages: List<JsonObject>): String = withContext(Dispatchers.IO) {
        val body = buildJsonObject {
            put("model", model)
            put("messages", JsonArray(messages))
            put("stream", false)

            // Same handling for pure Ollama vs OpenAI‚Äëproxy as above
            if (baseUrl.contains("ollama", ignoreCase = true).not()) {
                put("options", buildJsonObject {
                    put("response_format", "text")
                    put("tool_choice", "none")
                })
            }
        }

        val raw = http.post("$baseUrl/api/chat") {
            contentType(ContentType.Application.Json)
            bearerHeader()
            setBody(body)
        }.bodyAsText()

        val outer = Json.parseToJsonElement(raw).jsonObject
        outer["message"]!!.jsonObject["content"]!!.jsonPrimitive.content
    }

    /** -------------------------------------------------------------
    Helper ‚Äì extracts the **first** JSON object from a possibly noisy string.
    Throws IllegalArgumentException if no `{‚Ä¶}` can be found.
    ------------------------------------------------------------- */
    private fun extractJsonObject(text: String): String {
        // Trim whitespace first ‚Äì makes debugging output a little cleaner
        val trimmed = text.trim()
        val start = trimmed.indexOf('{')
        val end = trimmed.lastIndexOf('}')
        require(start != -1 && end != -1 && end > start) {
            "No JSON object could be detected in LLM output: $trimmed"
        }
        return trimmed.substring(start, end + 1)
    }
}
